# Local-LLM

## Requirements
ollama run llama3
fastapi
uvicorn
requests

## Running
The service is accessible via  http://127.0.0.1:8000/docs